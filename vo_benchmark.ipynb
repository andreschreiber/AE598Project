{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for two-view reconstruction without inertial data.\n",
    "\n",
    "Author: Andre Schreiber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import symforce\n",
    "symforce.set_epsilon_to_symbol()\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import time\n",
    "\n",
    "import vo\n",
    "# pose_metrics requires evo (see top of pose_metrics.py for install instructions)\n",
    "import pose_metrics\n",
    "import utils\n",
    "\n",
    "# Note: this notebook requires pandas in addition to all of Prof. Bretl's dependencies\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the dataset (should be 'kitti' or 'euroc')\n",
    "chosen_dataset = 'euroc'\n",
    "# chosen_dataset = 'kitti'\n",
    "\n",
    "assert(chosen_dataset in ['kitti', 'euroc'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When matching (max threshold for ratio test)\n",
    "if chosen_dataset == 'euroc': \n",
    "    matching_threshold = 0.5\n",
    "else:\n",
    "    matching_threshold = 0.3\n",
    "\n",
    "# When deciding if triangulated points are invalid\n",
    "max_reprojection_err = 0.75\n",
    "\n",
    "# Temporary folder for evo metrics\n",
    "temporary_folder = Path('./temp')\n",
    "temporary_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if chosen_dataset == 'euroc': # Note: euroc takes a bit longer to load.\n",
    "    # Use EuRoC MAV\n",
    "    \n",
    "    mav_video_folder = Path('./data/mav0')\n",
    "\n",
    "    # Read MAV data\n",
    "    dataset_info = utils.read_data_mav(mav_video_folder)\n",
    "    print(\"Read dataset with keys: {}\".format(sorted(list(dataset_info.keys()))))\n",
    "\n",
    "    # Extract relevant data\n",
    "    cam0_K = dataset_info['cam0_K']\n",
    "    cam0_distortion = dataset_info['cam0_distortion']\n",
    "    visual_inertial_data = dataset_info['visual_inertial_data']\n",
    "\n",
    "    sigma_acc_wn = dataset_info['imu_accelerometer_noise_density']\n",
    "    sigma_gyr_wn = dataset_info['imu_gyroscope_noise_density']\n",
    "    sigma_acc_rw = dataset_info['imu_accelerometer_noise_density']\n",
    "    sigma_gyr_rw = dataset_info['imu_gyroscope_random_walk']\n",
    "\n",
    "    dt = 1/200 # IMU frequency\n",
    "\n",
    "    # Get extrinsics\n",
    "    T_inB_ofC = dataset_info['cam0_extrinsics']\n",
    "    T_inC_ofB = np.block([[T_inB_ofC[:3,:3].T, (-T_inB_ofC[:3,:3].T @ T_inB_ofC[:3,-1])[:,np.newaxis]], [np.zeros(3), 1]])\n",
    "\n",
    "    # Collate\n",
    "    acc_meas, gyr_meas = utils.imu_collate(dataset_info['visual_inertial_data'])\n",
    "    R_inR_ofB, v_inR_ofB, p_inR_ofB, b_a, b_w = utils.groundtruth_collate(dataset_info['visual_inertial_data'], True)\n",
    "\n",
    "    # As EuRoC's ground-truth (MoCap) is not aligned with gravity (i.e., in world frame), we identify the orientation of MoCap frame in world frame\n",
    "    gravity = np.array([0., 0., -9.81])\n",
    "\n",
    "    g_inB = - np.mean(acc_meas[:10], axis=0)\n",
    "    g_inW = gravity\n",
    "\n",
    "    def align_vectors(g_inB, g_inW):\n",
    "        # Normalize input vectors\n",
    "        g_inB_unit = g_inB / np.linalg.norm(g_inB)\n",
    "        g_inW_unit = g_inW / np.linalg.norm(g_inW)\n",
    "\n",
    "        # Compute the axis of rotation\n",
    "        v = np.cross(g_inB_unit, g_inW_unit)\n",
    "\n",
    "        # Compute the angle of rotation\n",
    "        cos_theta = np.dot(g_inB_unit, g_inW_unit)\n",
    "        sin_theta = np.linalg.norm(v)\n",
    "        theta = np.arctan2(sin_theta, cos_theta)\n",
    "\n",
    "        v /= np.linalg.norm(v)\n",
    "        \n",
    "        # Compute the rotation matrix\n",
    "        Rot = R.from_rotvec(theta*v)\n",
    "        return Rot\n",
    "\n",
    "    # Compute rotation matrix\n",
    "    R_inW_ofB = align_vectors(g_inB, g_inW)\n",
    "    print(\"Rotation Matrix:\\n\", R_inW_ofB.as_matrix())\n",
    "\n",
    "    R_inW_ofB.apply(g_inB)\n",
    "\n",
    "    R_inW_ofR = R_inW_ofB * R_inR_ofB[:10].mean().inv()\n",
    "    R_inW_ofB = R_inW_ofR * R_inR_ofB\n",
    "    v_inW_ofB = R_inW_ofR.apply(v_inR_ofB)\n",
    "    p_inW_ofB = R_inW_ofR.apply(p_inR_ofB)\n",
    "\n",
    "else:\n",
    "    # Use KITTI\n",
    "\n",
    "    kitti_base_path = './data/kitti'\n",
    "    kitti_date = '2011_09_26'\n",
    "    kitti_drive = '0022'\n",
    "\n",
    "    # Read KITTI data\n",
    "    dataset_info = utils.read_data_kitti('./data/kitti', '2011_09_26', '0022')\n",
    "\n",
    "    # Extract relevant data\n",
    "    cam0_K = dataset_info['cam0_K']\n",
    "    cam0_distortion = dataset_info['cam0_distortion']\n",
    "    visual_inertial_data = dataset_info['visual_inertial_data']\n",
    "\n",
    "    T_inC_ofB = dataset_info['cam0_extrinsics']\n",
    "    R_inB_of_C = T_inC_ofB[:3, :3].T\n",
    "    t_inB_of_C = R_inB_of_C @ T_inC_ofB[:3, 3]\n",
    "    T_inB_ofC = np.block([[R_inB_of_C, t_inB_of_C[:,np.newaxis]], [np.zeros(3), 1]])\n",
    "    \n",
    "    R_inC_of_B = T_inC_ofB[:3, :3]\n",
    "    t_inC_of_B = T_inC_ofB[:3, 3]\n",
    "    \n",
    "\n",
    "    # Collate\n",
    "    acc_meas, gyr_meas = utils.imu_collate(visual_inertial_data)\n",
    "    R_inW_ofB, v_inW_ofB, p_inW_ofB, b_a, b_w = utils.groundtruth_collate(visual_inertial_data, False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create random generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rng = utils.create_rng(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create image keypoint feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = cv2.SIFT_create() # could also do ORB_create() for ORB features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two view reconstruction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get initial solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if chosen_dataset == 'euroc': # Note: euroc takes a bit longer to load.\n",
    "    # Use EuRoC MAV\n",
    "    chosen_index = 500\n",
    "    advance = 100\n",
    "else:\n",
    "    chosen_index = 50\n",
    "    advance = 5\n",
    "\n",
    "# Get first index closest to chosen index\n",
    "first_frame_idx = utils.get_index_of_next_image(visual_inertial_data, chosen_index)\n",
    "# Get second index\n",
    "second_frame_idx = utils.get_index_of_next_image(visual_inertial_data, first_frame_idx+advance)\n",
    "\n",
    "# Create two views\n",
    "views = [\n",
    "    vo.create_view_data(utils.read_image(visual_inertial_data[first_frame_idx]['image_file']),\n",
    "                        first_frame_idx, feature_extractor, cam0_K, cam0_distortion),\n",
    "    vo.create_view_data(utils.read_image(visual_inertial_data[second_frame_idx]['image_file']),\n",
    "                        second_frame_idx, feature_extractor, cam0_K, cam0_distortion)\n",
    "]\n",
    "\n",
    "# Perform two-view reconstruction\n",
    "tic = time.time()\n",
    "tracks = vo.vo_2view(views, matching_threshold, cam0_K, rng, use_opencv=False)\n",
    "toc = time.time()\n",
    "\n",
    "analyctical_guess = toc - tic\n",
    "print(f\"Analytical guess: {analyctical_guess:.2f} [s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vo.show_reproj_results(views, tracks, cam0_K, cam0_distortion, print_raw_reproj=True, show_reproj_histogram=True)\n",
    "vo.visualize_predictions(views, tracks, cam0_K, cam0_distortion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get post-optimization solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run below to keep the initial views and tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "views_ini = views.copy()\n",
    "tracks_ini = tracks.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "\n",
    "views, tracks, initial_values, results  = vo.vo_nonlinear_optimize(views_ini, tracks_ini, cam0_K, max_reprojection_err)\n",
    "\n",
    "toc = time.time()\n",
    "nonlinear = toc - tic\n",
    "print(f\"{nonlinear:.2f} [s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vo.show_reproj_results(views, tracks, cam0_K, cam0_distortion, print_raw_reproj=True, show_reproj_histogram=True)\n",
    "vo.visualize_predictions(views, tracks, cam0_K, cam0_distortion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTiming\\n{'='*100}\")\n",
    "print(f\"Analytical guess: {analyctical_guess:.2f} [s]\")\n",
    "print(f\"Non linear (VO): {nonlinear:.2f} [s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This highlights the scale ambiguity seen in two-view reconstruction\n",
    "print(\"Metric pose difference norm (gt) = {:.3f}\".format(np.linalg.norm(\n",
    "    # Note: while this is in world frame, the frames do not have any scaling,\n",
    "    # so measuring displacement this way still should provide the correct distance.\n",
    "    np.linalg.norm(p_inW_ofB[first_frame_idx] - p_inW_ofB[second_frame_idx])\n",
    ")))\n",
    "print(\"Metric pose difference norm (ini) = {:.3f}\".format(np.linalg.norm(results.initial_values['T_inB1_ofA'].t)))\n",
    "print(\"Metric pose difference norm (sf) = {:.3f}\".format(np.linalg.norm(results.optimized_values['T_inB1_ofA'].t)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
