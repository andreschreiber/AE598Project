{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for two-view reconstruction without inertial data.\n",
    "\n",
    "Author: Andre Schreiber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import symforce\n",
    "symforce.set_epsilon_to_symbol()\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import time\n",
    "\n",
    "import vo\n",
    "# pose_metrics requires evo (see top of pose_metrics.py for install instructions)\n",
    "import pose_metrics\n",
    "import utils\n",
    "\n",
    "# Note: this notebook requires pandas in addition to all of Prof. Bretl's dependencies\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When matching (max threshold for ratio test)\n",
    "matching_threshold = 0.1 # I recommend 0.1 for KITTI and 0.5 for EuRoC\n",
    "\n",
    "# When deciding if triangulated points are invalid\n",
    "max_reprojection_err = 0.75\n",
    "\n",
    "# Temporary folder for evo metrics\n",
    "temporary_folder = Path('./temp')\n",
    "temporary_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the dataset (should be 'kitti' or 'euroc')\n",
    "chosen_dataset = 'euroc'\n",
    "\n",
    "assert(chosen_dataset in ['kitti', 'euroc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if chosen_dataset == 'euroc': # Note: euroc takes a bit longer to load.\n",
    "    # Use EuRoC MAV\n",
    "    \n",
    "    mav_video_folder = Path('./data/mav0')\n",
    "\n",
    "    # Read MAV data\n",
    "    dataset_info = utils.read_data_mav(mav_video_folder)\n",
    "    print(\"Read dataset with keys: {}\".format(sorted(list(dataset_info.keys()))))\n",
    "\n",
    "    # Extract relevant data\n",
    "    cam0_K = dataset_info['cam0_K']\n",
    "    cam0_distortion = dataset_info['cam0_distortion']\n",
    "    visual_inertial_data = dataset_info['visual_inertial_data']\n",
    "\n",
    "    sigma_acc_wn = dataset_info['imu_accelerometer_noise_density']\n",
    "    sigma_gyr_wn = dataset_info['imu_gyroscope_noise_density']\n",
    "    sigma_acc_rw = dataset_info['imu_accelerometer_noise_density']\n",
    "    sigma_gyr_rw = dataset_info['imu_gyroscope_random_walk']\n",
    "\n",
    "    dt = 1/200 # IMU frequency\n",
    "\n",
    "    # Get extrinsics\n",
    "    T_inB_ofC = dataset_info['cam0_extrinsics']\n",
    "    T_inC_ofB = np.block([[T_inB_ofC[:3,:3].T, (-T_inB_ofC[:3,:3].T @ T_inB_ofC[:3,-1])[:,np.newaxis]], [np.zeros(3), 1]])\n",
    "\n",
    "    # Collate\n",
    "    acc_meas, gyr_meas = utils.imu_collate(dataset_info['visual_inertial_data'])\n",
    "    R_inR_ofB, v_inR_ofB, p_inR_ofB, b_a, b_w = utils.groundtruth_collate(dataset_info['visual_inertial_data'], True)\n",
    "\n",
    "    # As EuRoC's ground-truth (MoCap) is not aligned with gravity (i.e., in world frame), we identify the orientation of MoCap frame in world frame\n",
    "    gravity = np.array([0., 0., -9.81])\n",
    "\n",
    "    g_inB = - np.mean(acc_meas[:10], axis=0)\n",
    "    g_inW = gravity\n",
    "\n",
    "    def align_vectors(g_inB, g_inW):\n",
    "        # Normalize input vectors\n",
    "        g_inB_unit = g_inB / np.linalg.norm(g_inB)\n",
    "        g_inW_unit = g_inW / np.linalg.norm(g_inW)\n",
    "\n",
    "        # Compute the axis of rotation\n",
    "        v = np.cross(g_inB_unit, g_inW_unit)\n",
    "\n",
    "        # Compute the angle of rotation\n",
    "        cos_theta = np.dot(g_inB_unit, g_inW_unit)\n",
    "        sin_theta = np.linalg.norm(v)\n",
    "        theta = np.arctan2(sin_theta, cos_theta)\n",
    "\n",
    "        v /= np.linalg.norm(v)\n",
    "        \n",
    "        # Compute the rotation matrix\n",
    "        Rot = R.from_rotvec(theta*v)\n",
    "        return Rot\n",
    "\n",
    "    # Compute rotation matrix\n",
    "    R_inW_ofB = align_vectors(g_inB, g_inW)\n",
    "    print(\"Rotation Matrix:\\n\", R_inW_ofB.as_matrix())\n",
    "\n",
    "    R_inW_ofB.apply(g_inB)\n",
    "\n",
    "    R_inW_ofR = R_inW_ofB * R_inR_ofB[:10].mean().inv()\n",
    "    R_inW_ofB = R_inW_ofR * R_inR_ofB\n",
    "    v_inW_ofB = R_inW_ofR.apply(v_inR_ofB)\n",
    "    p_inW_ofB = R_inW_ofR.apply(p_inR_ofB)\n",
    "\n",
    "else:\n",
    "    # Use KITTI\n",
    "\n",
    "    kitti_base_path = './data/kitti'\n",
    "    kitti_date = '2011_09_26'\n",
    "    kitti_drive = '0022'\n",
    "\n",
    "    # Read KITTI data\n",
    "    dataset_info = utils.read_data_kitti('./data/kitti', '2011_09_26', '0022')\n",
    "\n",
    "    # Extract relevant data\n",
    "    cam0_K = dataset_info['cam0_K']\n",
    "    cam0_distortion = dataset_info['cam0_distortion']\n",
    "    visual_inertial_data = dataset_info['visual_inertial_data']\n",
    "\n",
    "    T_inC_ofB = dataset_info['cam0_extrinsics']\n",
    "    \n",
    "    # Collate\n",
    "    acc_meas, gyr_meas = utils.imu_collate(visual_inertial_data)\n",
    "    R_inW_ofB, v_inW_ofB, p_inW_ofB, b_a, b_w = utils.groundtruth_collate(visual_inertial_data, False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create random generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = utils.create_rng(None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create image keypoint feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = cv2.SIFT_create() # could also do ORB_create() for ORB features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two view reconstruction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get initial solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_index = 5000\n",
    "advance = 10\n",
    "\n",
    "# Get first index closest to chosen index\n",
    "first_frame_idx = utils.get_index_of_next_image(visual_inertial_data, chosen_index)\n",
    "# Get second index\n",
    "second_frame_idx = utils.get_index_of_next_image(visual_inertial_data, first_frame_idx+advance)\n",
    "\n",
    "# Create two views\n",
    "views = [\n",
    "    vo.create_view_data(utils.read_image(visual_inertial_data[first_frame_idx]['image_file']),\n",
    "                        first_frame_idx, feature_extractor, cam0_K, cam0_distortion),\n",
    "    vo.create_view_data(utils.read_image(visual_inertial_data[second_frame_idx]['image_file']),\n",
    "                        second_frame_idx, feature_extractor, cam0_K, cam0_distortion)\n",
    "]\n",
    "\n",
    "# Perform two-view reconstruction\n",
    "tracks = vo.vo_2view(views, matching_threshold, cam0_K, rng, use_opencv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vo.show_reproj_results(views, tracks, cam0_K, cam0_distortion, print_raw_reproj=True, show_reproj_histogram=True)\n",
    "vo.visualize_predictions(views, tracks, cam0_K, cam0_distortion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get post-optimization solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run below to keep the initial views and tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "views_ini = views.copy()\n",
    "tracks_ini = tracks.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "\n",
    "views, tracks, initial_values, results  = vo.vo_nonlinear_optimize(views_ini, tracks_ini, cam0_K, max_reprojection_err)\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "print(f\"{toc - tic:.2f} [s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vo.show_reproj_results(views, tracks, cam0_K, cam0_distortion, print_raw_reproj=True, show_reproj_histogram=True)\n",
    "vo.visualize_predictions(views, tracks, cam0_K, cam0_distortion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate change in position between frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth\n",
    "R_inW_ofB0_gt = R_inW_ofB[first_frame_idx].as_matrix()\n",
    "p_inW_ofB0_gt = p_inW_ofB[first_frame_idx]\n",
    "\n",
    "R_inW_ofB1_gt = R_inW_ofB[second_frame_idx].as_matrix()\n",
    "p_inW_ofB1_gt = p_inW_ofB[second_frame_idx]\n",
    "\n",
    "R_inB0_ofW_gt = R_inW_ofB0_gt.T\n",
    "p_inB0_ofW_gt = - R_inW_ofB0_gt.T @ p_inW_ofB0_gt\n",
    "\n",
    "R_inB1_ofW_gt = R_inW_ofB1_gt.T\n",
    "p_inB1_ofW_gt = - R_inW_ofB1_gt.T @ p_inW_ofB1_gt\n",
    "\n",
    "R_inC_ofB = T_inC_ofB[:3,:3]\n",
    "p_inC_ofB = T_inC_ofB[:3,-1]\n",
    "\n",
    "R_inB_ofC = T_inB_ofC[:3,:3]\n",
    "p_inB_ofC = T_inB_ofC[:3,-1]\n",
    "\n",
    "R_inC0_ofW_gt = R_inC_ofB @ R_inB0_ofW_gt\n",
    "p_inC0_ofW_gt = R_inC_ofB @ p_inB0_ofW_gt + p_inC_ofB\n",
    "\n",
    "R_inC1_ofW_gt = R_inC_ofB @ R_inB1_ofW_gt\n",
    "p_inC1_ofW_gt = R_inC_ofB @ p_inB1_ofW_gt + p_inC_ofB\n",
    "\n",
    "R_inW_ofC0_gt = R_inW_ofB0_gt @ R_inB_ofC\n",
    "p_inW_ofC0_gt = R_inW_ofB0_gt @ p_inB_ofC + p_inW_ofB0_gt\n",
    "\n",
    "R_inW_ofC1_gt = R_inW_ofB1_gt @ R_inB_ofC\n",
    "p_inW_ofC1_gt = R_inW_ofB1_gt @ p_inB_ofC + p_inW_ofB0_gt\n",
    "\n",
    "# Symforce - Initial values\n",
    "R_inC0_ofW_ini = results.initial_values['T_inB0_ofA'].R.to_rotation_matrix() @ R_inC0_ofW_gt\n",
    "p_inC0_ofW_ini = results.initial_values['T_inB0_ofA'].R.to_rotation_matrix() @ p_inC0_ofW_gt + results.initial_values['T_inB0_ofA'].t\n",
    "\n",
    "R_inC1_ofW_ini = results.initial_values['T_inB1_ofA'].R.to_rotation_matrix() @ R_inC1_ofW_gt\n",
    "p_inC1_ofW_ini = results.initial_values['T_inB1_ofA'].R.to_rotation_matrix() @ p_inC1_ofW_gt + results.initial_values['T_inB1_ofA'].t\n",
    "\n",
    "R_inW_ofC0_ini = R_inC0_ofW_ini.T\n",
    "p_inW_ofC0_ini = - R_inC0_ofW_ini.T @ p_inC0_ofW_ini\n",
    "\n",
    "R_inW_ofC1_ini = R_inC1_ofW_ini.T\n",
    "p_inW_ofC1_ini = - R_inC1_ofW_ini.T @ p_inC1_ofW_ini\n",
    "\n",
    "# Symforce - Optimized values\n",
    "R_inC0_ofW_sf = results.optimized_values['T_inB0_ofA'].R.to_rotation_matrix() @ R_inC0_ofW_gt\n",
    "p_inC0_ofW_sf = results.optimized_values['T_inB0_ofA'].R.to_rotation_matrix() @ p_inC0_ofW_gt + results.optimized_values['T_inB0_ofA'].t\n",
    "\n",
    "R_inC1_ofW_sf = results.optimized_values['T_inB1_ofA'].R.to_rotation_matrix() @ R_inC1_ofW_gt\n",
    "p_inC1_ofW_sf = results.optimized_values['T_inB1_ofA'].R.to_rotation_matrix() @ p_inC1_ofW_gt + results.optimized_values['T_inB1_ofA'].t\n",
    "\n",
    "R_inW_ofC0_sf = R_inC0_ofW_sf.T\n",
    "p_inW_ofC0_sf = - R_inC0_ofW_sf.T @ p_inC0_ofW_sf\n",
    "\n",
    "R_inW_ofC1_sf = R_inC1_ofW_sf.T\n",
    "p_inW_ofC1_sf = - R_inC1_ofW_sf.T @ p_inC1_ofW_sf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error evaluation on optimized results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_inW_ofC0toC1_ini = p_inW_ofC1_ini - p_inW_ofC0_ini\n",
    "R_inC1_ofC0_ini = R_inW_ofC1_ini.T @ R_inW_ofC0_ini\n",
    "\n",
    "p_inW_ofC0toC1_sf = p_inW_ofC1_sf - p_inW_ofC0_sf\n",
    "R_inC1_ofC0_sf = R_inW_ofC1_sf.T @ R_inW_ofC0_sf\n",
    "\n",
    "p_inW_ofC0toC1_gt = p_inW_ofC1_gt - p_inW_ofC0_gt\n",
    "R_inC1_ofC0_gt = R_inW_ofC1_gt.T @ R_inW_ofC0_gt\n",
    "\n",
    "dR_err_ini = R.from_matrix(R_inC1_ofC0_ini.T @ R_inC1_ofC0_gt).as_euler('xyz', degrees=True)\n",
    "dR_err_sf = R.from_matrix(R_inC1_ofC0_sf.T @ R_inC1_ofC0_gt).as_euler('xyz', degrees=True)\n",
    "print(f'dR: {dR_err_ini} (init.) --> {dR_err_sf} (optm.) [deg] (xyz)')\n",
    "print('dR scalar: {:.5f} (init.) --> {:.5f} (optm.) [deg]'.format(\n",
    "    pose_metrics.rotational_error(R_inC1_ofC0_ini, R_inC1_ofC0_gt),\n",
    "    pose_metrics.rotational_error(R_inC1_ofC0_sf, R_inC1_ofC0_gt),\n",
    "))\n",
    "\n",
    "dp_err_ini = p_inW_ofC0toC1_ini - p_inW_ofC0toC1_gt\n",
    "dp_err_sf = p_inW_ofC0toC1_sf - p_inW_ofC0toC1_gt\n",
    "print(f'dp: {np.linalg.norm(dp_err_ini):.2f} (init.) --> {np.linalg.norm(dp_err_sf):.2f} (optm.) [m]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ae598-3dv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
